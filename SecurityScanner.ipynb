{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy\n",
    "import shutil\n",
    "import requests\n",
    "import http_parser\n",
    "import xml.etree.ElementTree as ET\n",
    "import html as HTML\n",
    "\n",
    "from lxml import etree, html\n",
    "from collections import Counter\n",
    "\n",
    "try:\n",
    "    from http_parser.parser import HttpParser\n",
    "except ImportError:\n",
    "    from http_parser.pyparser import HttpParser\n",
    "    \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "VAR_SEARCH_REGEXP = [\n",
    "                     ur\"([a-zA-Z_]\\w*)\\[([a-zA-Z_]\\w*)*\\w*\\]\", # array regexp\n",
    "                     ur\"var\\s+([a-zA-Z_]\\w*)\",                 # var name regexp   \n",
    "                     ur\"([a-zA-Z_]\\w*)\\.([a-zA-Z_]\\w*)\\.*\",    # class hierarchy\n",
    "                     ur\"([a-zA-Z_]\\w*)\\s*=\\s*\\w\",              # name = value\n",
    "                     ur\"\\w+\\s*=\\s*([a-zA-Z_]\\w*)\",             # smth = name \n",
    "                     ur'''[\\\"\\']([a-zA-Z_]\\w*)[\\\"\\']:[\\\"\\']\\w*[\\\"\\']''' # \"name\":\"value\"\n",
    "                    ]\n",
    "\n",
    "JAVASCRIPT_KEYWORDS = set([\n",
    "                        'abstract','arguments','boolean','break','byte',\n",
    "                        'case','catch','char','class*','const',\n",
    "                        'continue','debugger','default','delete','do',\n",
    "                        'double','else','enum*','eval','export*',\n",
    "                        'extends*','false','final','finally','float',\n",
    "                        'for','function','goto','if','implements',\n",
    "                        'import','in','instanceof','int','interface',\n",
    "                        'let','long','native','new','null',\n",
    "                        'package','private','protected','public','return',\n",
    "                        'short','static','super*','switch','synchronized',\n",
    "                        'this','throw','throws','transient','true',\n",
    "                        'try','typeof','var','void','volatile',\n",
    "                        'while','with','yield'\n",
    "                    ])\n",
    "\n",
    "BURPSUITE_PROXIES = {\n",
    "      'http': '127.0.0.1:8080',\n",
    "      'https': '127.0.0.1:8080'\n",
    "    }\n",
    "\n",
    "CERT_FILE = \"/home/ruslan/PortSwiggerCA.crt\"                  # Correct path to Burp Suite crt file\n",
    "                                                              # I add cacert.der to Firefox, and then  \n",
    "SEVERITY_CLASSIFICATION = {                                   # import this .crt file \n",
    "    \"Hight\":5, \n",
    "    \"Medium\":3,\n",
    "    \"Low\":1,\n",
    "    \"Undefined\":-1\n",
    "}\n",
    "\n",
    "TEST_PAYLOAD_DICT = {\n",
    "    \"a87ui\":\"High\",\n",
    "    \"87923\":\"Low\",\n",
    "}\n",
    "\n",
    "COMMON_PAYLOADS_DICT = {\n",
    "                        \"amF2YXNjcmlwdDphbGVydCgxKTsvLy8=\":\"Hight\",\n",
    "                        \"\\\"-alert-\\\"\":\"Hight\",\n",
    "                        \"amF2YXNjcmlwdDphbGVydCgxKTs=\":\"Medium\",\n",
    "                        \"javascript:alert(1)\":\"Medium\",\n",
    "                        \"alert(1)\":\"Low\"\n",
    "                        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Http Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class HttpResponse:\n",
    "    def __init__(self,http_plain):\n",
    "        self.ResponseParser = HttpParser()\n",
    "        self.ResponseParser.execute(http_plain,len(http_plain))\n",
    "        \n",
    "    def GetContent(self):\n",
    "        return self.ResponseParser.recv_body()\n",
    "        \n",
    "    def GetHeaders(self):\n",
    "        if self.ResponseParser.is_headers_complete():\n",
    "            return dict(self.ResponseParser.get_headers())\n",
    "        else:\n",
    "            return dict()\n",
    "        \n",
    "class HttpRequest:\n",
    "    def __init__(self,http_plain):\n",
    "        self.RequestParser = HttpParser()\n",
    "        self.RequestParser.execute(http_plain,len(http_plain))\n",
    "        \n",
    "    def GetContent(self):\n",
    "        return self.RequestParser.recv_body()\n",
    "        \n",
    "    def GetHeaders(self):\n",
    "        if self.RequestParser.is_headers_complete():\n",
    "            return dict(self.RequestParser.get_headers())\n",
    "        else:\n",
    "            return dict()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Burp Suite History Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class BurpHistoryItem:\n",
    "    def __init__(self,item):\n",
    "        self.item = item\n",
    "        \n",
    "        base64_response = self.item.findall(\".//response\")[0].text\n",
    "        self.response_plain = base64_response.decode('base64')\n",
    "        self.Response = HttpResponse(self.response_plain)\n",
    "        \n",
    "        base64_request = self.item.findall(\".//request\")[0].text\n",
    "        self.request_plain = base64_request.decode('base64')\n",
    "        self.Request = HttpRequest(self.request_plain)\n",
    "        \n",
    "        \n",
    "    def GetUrl(self):\n",
    "        url = self.item.findall(\".//url\")[0]\n",
    "        return url.text\n",
    "    \n",
    "    def GetHost(self):\n",
    "        host = self.item.findall(\".//host\")[0]\n",
    "        return host.text\n",
    "    \n",
    "    def GetHostIP(self):\n",
    "        host = self.item.findall(\".//host\")[0]\n",
    "        ip = host.attrib[\"ip\"]\n",
    "        return ip\n",
    "    \n",
    "    def GetPort(self):\n",
    "        port = self.item.findall(\".//port\")[0]\n",
    "        return int(port)\n",
    "    \n",
    "    def GetProtocol(self):\n",
    "        protocol = self.item.findall(\".//protocol\")[0]\n",
    "        return protocol\n",
    "    \n",
    "    def GetMethod(self):\n",
    "        method = self.item.findall(\".//method\")[0]\n",
    "        return method.text\n",
    "    \n",
    "    def GetPath(self):\n",
    "        path = self.item.findall(\".//path\")[0]\n",
    "        return path.text\n",
    "    \n",
    "    def GetExtension(self):\n",
    "        extension = self.item.findall(\".//extension\")[0]\n",
    "        return extension.text\n",
    "    \n",
    "    def GetHttpRequestData(self):\n",
    "        return self.request_plain\n",
    "    \n",
    "    def GetRequest(self):\n",
    "        return self.Request\n",
    "    \n",
    "    def GetStatus(self):\n",
    "        status = self.item.findall(\".//status\")[0].text\n",
    "        return int(status.text)\n",
    "    \n",
    "    def GetResponseLength(self):\n",
    "        responselength = self.item.findall(\".//responselength\")[0].text\n",
    "        return int(responselength)\n",
    "    \n",
    "    def GetResponse(self):\n",
    "        return self.Response\n",
    "    \n",
    "    def GetMiemType(self):\n",
    "        miem_type = self.item.findall(\".//mimetype\")[0].text\n",
    "        \n",
    "    def GetHttpResponseData(self):\n",
    "        return self.response_plain\n",
    "    \n",
    "    def GetComment(self):\n",
    "        comment = self.item.findall(\".//comment\")[0].text\n",
    "        if comment != None:\n",
    "            return comment\n",
    "        else:\n",
    "            return \"\"\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def GetListOfHistItemsFromFile(filename):\n",
    "    xmlTree = ET.parse(filename)\n",
    "    xmlRoot = xmlTree.getroot()\n",
    "    \n",
    "    HistoryItemList = list()\n",
    "    \n",
    "    for item in xmlTree.findall(\"//item\"):\n",
    "        tempHistoryItem = BurpHistoryItem(item)\n",
    "        HistoryItemList.append(tempHistoryItem)\n",
    "    \n",
    "    return HistoryItemList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def MatchUrl(text):\n",
    "    result_urls = list()\n",
    "    \n",
    "    # Search for:\n",
    "    # url: http://url\n",
    "    # url: https://url\n",
    "    # url: //url \n",
    "    \n",
    "    url_regexp = ur\"http[s]?:\\/\\/[\\w\\/\\\\\\%\\.\\?\\&\\=\\-]+|\\/\\/[\\w\\/\\\\\\%\\.\\?\\&\\=\\-]+\"\n",
    "    \n",
    "    for url in re.finditer(url_regexp, text):\n",
    "        result_urls.append(url.group())\n",
    "    return result_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def GetUrlParams(Url): # TODO Wtf ? Delete this shit ?!\n",
    "    if Url.find('?') != -1:\n",
    "        return re.findall(\"(\\?.+)\",Url)[0]\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def EscapeString(string):\n",
    "    \n",
    "    HTMLEscapeTable = {\n",
    "     \"&\": \"&amp;\",\n",
    "     '\"': \"&quot;\",\n",
    "     \"'\": \"&apos;\",\n",
    "     \">\": \"&gt;\",\n",
    "     \"<\": \"&lt;\",\n",
    "     }\n",
    "\n",
    "    return \"\".join(HTMLEscapeTable.get(c,c) for c in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def AddPayloadToUrl(Url,VarName,Payload):\n",
    "    ResultUrl = Url\n",
    "    if Url.find('?') != -1:\n",
    "        ResultUrl += \"&\"+VarName+\"=\"+Payload\n",
    "    else:\n",
    "        ResultUrl += \"?\"+VarName+\"=\"+Payload\n",
    "    return ResultUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def GetPostVariables(Content):\n",
    "    VarRegExp = ur\"([a-zA-Z_]\\w*)=(\\w*);?\"\n",
    "    DictOfVars = dict()\n",
    "    for Match in re.finditer(VarRegExp,Content):\n",
    "        try:\n",
    "            VarName = Match.groups()[0]\n",
    "            VarValue = Match.groups()[1]\n",
    "            DictOfVars[VarName] = VarValue\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return DictOfVars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Variable Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def FindJSVariables(PlainHtml):\n",
    "    SetOfVariables = set()\n",
    "    HTMLDocument = html.fromstring(PlainHtml)\n",
    "    \n",
    "    PageScripts = HTMLDocument.xpath(\".//script\")\n",
    "    VarList = list()\n",
    "    \n",
    "    for Script in PageScripts:\n",
    "        ScriptContent = Script.text\n",
    "        if ScriptContent == None:\n",
    "            continue\n",
    "            \n",
    "        for RegExp in VAR_SEARCH_REGEXP:\n",
    "            try:  \n",
    "                for Matched in re.finditer(RegExp,ScriptContent):\n",
    "                    for VarName in Matched.groups():\n",
    "                        if False == (VarName == None):\n",
    "                            if VarName not in JAVASCRIPT_KEYWORDS:\n",
    "                                VarList.append(VarName)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    VarList = list(set(VarList))\n",
    "    VarList = [item.strip(' ') for item in VarList]\n",
    "    \n",
    "    return VarList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FormVarsExtractor(PlainHtml,GrabableAttributes = ['name']):\n",
    "    SetOfVariables = set()\n",
    "    HTMLDocument = html.fromstring(PlainHtml)\n",
    "    PageInputs = HTMLDocument.xpath(\".//input\")\n",
    "    VarList = list()\n",
    "\n",
    "    for Input in PageInputs:\n",
    "        for Attribute in GrabableAttributes:\n",
    "            if Attribute in Input.attrib:\n",
    "                VarList.append(Input.attrib[Attribute])\n",
    "                \n",
    "    VarList = list(set(VarList))\n",
    "    return VarList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ScanSiteFromBurpHistory(HistItem,Payloads,UseProxy=True):\n",
    "    \n",
    "    Url = HistItem.GetUrl()\n",
    "    Headers = HistItem.GetRequest().GetHeaders()\n",
    "    \n",
    "    try:\n",
    "        if UseProxie == True:\n",
    "            Response = requests.get(Url,headers=Headers,proxies=BURPSUITE_PROXIES, verify=CERT_FILE)\n",
    "        else:\n",
    "            Response = requests.get(Url,headers=Headers)      \n",
    "    except:\n",
    "        print \"Could not download requested page!\\n%s\"%(Url)\n",
    "        return\n",
    "        \n",
    "    JSVariableNames = FindJSVariables(Response.text)\n",
    "    FormVariableNames = FormVarsExtractor(Responce.text) \n",
    "    \n",
    "    print \"Scanning %s Testing method: GET\\n Try %d variables and %d types of payloads\"%(\n",
    "                                                    Url,\n",
    "                                                    len(JSVariableNames)+len(FormVariableNames),\n",
    "                                                    len(Payloads))\n",
    "    \n",
    "    for VariableName in set(JSVariableNames + FormVariableNames):\n",
    "        PayloadCounter = Counter()\n",
    "        for Payload in Payloads:\n",
    "            TestUrl = AddPayloadToUrl(Url,VariableName,Payload)\n",
    "            try:\n",
    "                if UseProxie == True:\n",
    "                    Response = requests.get(TestUrl,headers=Headers,proxies=BURPSUITE_PROXIES, verify=CERT_FILE)\n",
    "                else:\n",
    "                    Responce = requests.get(TestUrl,headers=Headers)\n",
    "            except:\n",
    "                print \"Failed to load %s \\nPage excluded from analys list\"%(TestUrl)\n",
    "                \n",
    "            PlainHtml = Response.text     \n",
    "            PlainHtml = re.sub(re.escape(TestUrl),\"\",PlainHtml)\n",
    "            \n",
    "            TestUrlParam = GetUrlParams(TestUrl)\n",
    "            PlainHtml = re.sub(re.escape(TestUrlParam),\"\",PlainHtml)\n",
    "            \n",
    "            if  PlainHtml.find(Payload) != -1:\n",
    "                for Match in re.finditer(Payload,PlainHtml):\n",
    "                    PayloadCounter[Payload] += 1\n",
    "                    print Match.groups()\n",
    "                        \n",
    "                print \"Variable %s contain value %s with severity %s which occur %d times\\n\" %(\n",
    "                                                VariableName,\n",
    "                                                Payload,\n",
    "                                                Payloads[Payload],\n",
    "                                                PayloadCounter[Payload]\n",
    "                                                )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ProcessResultConcurrent(Arguments):\n",
    "    \n",
    "    RequestParams = Arguments[0]\n",
    "    PayloadParams = Arguments[1]\n",
    "    UseProxy = Arguments[2]\n",
    "    LogFile = Arguments[3]\n",
    "    \n",
    "    ScanUrl, Headers = RequestParams\n",
    "    Payload, Severity = PayloadParams\n",
    "    log = \"\"\n",
    "    \n",
    "    if UseProxy == True:\n",
    "        Response = requests.get(ScanUrl,headers=Headers,proxies=BURPSUITE_PROXIES, verify=CERT_FILE)\n",
    "    else:\n",
    "        Response = requests.get(ScanUrl,headers=Headers)\n",
    "        \n",
    "    PlainHtml = Response.text     \n",
    "    PlainHtml = re.sub(re.escape(ScanUrl),\"\",PlainHtml)\n",
    "            \n",
    "    # TestUrlParam = GetUrlParams(TestUrl)\n",
    "    # PlainHtml = re.sub(re.escape(TestUrlParam),\"\",PlainHtml) # TODO Delete this shit!\n",
    "    \n",
    "    PayloadCounter = Counter()\n",
    "    \n",
    "    if  PlainHtml.find(Payload) != -1:\n",
    "        for Match in re.finditer(Payload,PlainHtml):\n",
    "            PayloadCounter[Payload] += 1\n",
    "                        \n",
    "        log += \"Page %s\\n Contain value %s with severity %s which occur %d times\\n\" %(\n",
    "                                                ScanUrl,\n",
    "                                                Payload,\n",
    "                                                Severity,\n",
    "                                                PayloadCounter[Payload]\n",
    "                                                )\n",
    "        with open(LogFile,'a') as f:\n",
    "            f.write(log)\n",
    "    \n",
    "def ScanSiteItemConcurrent(MaxWorkers,HistItem,Payloads,BatchSize,UseProxy,LogFile):\n",
    "    Url = HistItem.GetUrl()\n",
    "    Headers = HistItem.GetRequest().GetHeaders()\n",
    "    Response = HistItem.GetHttpResponseData()\n",
    "    \n",
    "    JSVariableNames = set(FindJSVariables(Response))\n",
    "    FormVariableNames = set(FormVarsExtractor(Response))\n",
    "    \n",
    "    Variables = set()\n",
    "    Variables = Variables.union(JSVariableNames)\n",
    "    Variables = Variables.union(FormVariableNames)\n",
    "    \n",
    "    log = \"\"\n",
    "    log += \"Scanning %s Testing method: GET\\n Try %d variables and %d types of payloads\\n\"%(\n",
    "                                                    Url,\n",
    "                                                    len(Variables),\n",
    "                                                    len(Payloads))\n",
    "    with open(LogFile,'a') as f:\n",
    "        f.write(log)\n",
    "    \n",
    "    ScanningQueue = list()\n",
    "    BatchCommit = []\n",
    "    \n",
    "    for VariableName in Variables:\n",
    "        PayloadCounter = Counter()\n",
    "        BatchCommit.append(VariableName)\n",
    "        \n",
    "        if len(BatchCommit) >= BatchSize:\n",
    "            for Payload in Payloads:\n",
    "                ScanURL = Url\n",
    "                for BatchVarName in BatchCommit:\n",
    "                    ScanURL = AddPayloadToUrl(ScanURL,BatchVarName,Payload)\n",
    "        \n",
    "                ScanningQueue.append([(ScanURL,Headers),(Payload,Payloads[Payload]),UseProxy,LogFile])\n",
    "            BatchCommit = []\n",
    "            \n",
    "    with ThreadPoolExecutor(max_workers = MaxWorkers) as Executor:\n",
    "        for _ in Executor.map(ProcessResultConcurrent,ScanningQueue):\n",
    "            pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Simple vulnerabilities scanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#BurpHistoryFile = os.getcwd()+\"/hist\"\n",
    "#BurpHistItems = GetListOfHistItemsFromFile(BurpHistoryFile)\n",
    "#\n",
    "#for item in BurpHistItems:\n",
    "#    ScanSiteFromBurpHistory(item,COMMON_PAYLOADS_DICT,UseProxie=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Concurrent Scanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:7: FutureWarning: This search is broken in 1.3 and earlier, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/item'\n"
     ]
    }
   ],
   "source": [
    "BurpHistoryFile = '/home/ruslan/icq_hist'\n",
    "BurpHistItems = GetListOfHistItemsFromFile(BurpHistoryFile)\n",
    "\n",
    "with open('/home/ruslan/icq_scan.log','w') as f:\n",
    "    f.write('Scan start...\\n')\n",
    "\n",
    "for item in BurpHistItems:\n",
    "    ScanSiteItemConcurrent(6,item,COMMON_PAYLOADS_DICT,BatchSize=5,UseProxy=True,LogFile='/home/ruslan/icq_scan.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test & Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"https://e.mail.ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "VarList = list()\n",
    "for j in VAR_SEARCH_REGEXP:\n",
    "    for i in re.finditer(j,response.text):\n",
    "        for k in i.groups():\n",
    "            if False == (k == None):\n",
    "                if k not in JAVASCRIPT_KEYWORDS:\n",
    "                    VarList.append(k)\n",
    "\n",
    "WordCounter = Counter()\n",
    "for item in VarList:\n",
    "    WordCounter[item] += 1\n",
    "    \n",
    "for item in WordCounter:\n",
    "    print \"%s : %d\"%(item,WordCounter[item])\n",
    "    \n",
    "print len([item for item in WordCounter])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(\"https://search.icq.com/\")\n",
    "doc = html.fromstring(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alrt_yes\n"
     ]
    }
   ],
   "source": [
    "if 'id' in doc.xpath(\".//input\")[0].attrib:\n",
    "    print doc.xpath(\".//input\")[0].attrib['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['range', 'prtn', 'ch_id', 'search_keyword']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FormVarsExtractor(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
